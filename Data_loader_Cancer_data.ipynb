{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f05910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "from sklearn.model_selection import train_test_split,RepeatedStratifiedKFold,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c50981a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"Data\\Cancer_data\\Reduction_from_Random_Forest.csv\")\n",
    "data=data.sample(frac=1,ignore_index=True)\n",
    "labels=data['label']\n",
    "data=data.iloc[:,1:-7]\n",
    "\n",
    "\n",
    "# labels=data['label']\n",
    "# data=data.drop(['class','BRCA','COAD','KIRC','LUAD','PRAD'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4dd281c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_9927</th>\n",
       "      <th>gene_9928</th>\n",
       "      <th>gene_9929</th>\n",
       "      <th>gene_993</th>\n",
       "      <th>gene_9930</th>\n",
       "      <th>gene_9931</th>\n",
       "      <th>gene_9932</th>\n",
       "      <th>gene_9933</th>\n",
       "      <th>gene_9934</th>\n",
       "      <th>gene_9935</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_9990</th>\n",
       "      <th>gene_9991</th>\n",
       "      <th>gene_9992</th>\n",
       "      <th>gene_9993</th>\n",
       "      <th>gene_9994</th>\n",
       "      <th>gene_9995</th>\n",
       "      <th>gene_9996</th>\n",
       "      <th>gene_9997</th>\n",
       "      <th>gene_9998</th>\n",
       "      <th>gene_9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.00000</td>\n",
       "      <td>801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.133506</td>\n",
       "      <td>0.031187</td>\n",
       "      <td>0.114169</td>\n",
       "      <td>0.576883</td>\n",
       "      <td>0.167557</td>\n",
       "      <td>0.120448</td>\n",
       "      <td>0.076820</td>\n",
       "      <td>0.579498</td>\n",
       "      <td>0.130505</td>\n",
       "      <td>0.181222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270382</td>\n",
       "      <td>0.336316</td>\n",
       "      <td>0.339964</td>\n",
       "      <td>0.363043</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.467481</td>\n",
       "      <td>0.030963</td>\n",
       "      <td>0.336231</td>\n",
       "      <td>0.06967</td>\n",
       "      <td>0.561714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.230714</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.124997</td>\n",
       "      <td>0.239211</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.115456</td>\n",
       "      <td>0.156195</td>\n",
       "      <td>0.167667</td>\n",
       "      <td>0.162166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>0.282232</td>\n",
       "      <td>0.195718</td>\n",
       "      <td>0.162130</td>\n",
       "      <td>0.201622</td>\n",
       "      <td>0.186034</td>\n",
       "      <td>0.083459</td>\n",
       "      <td>0.235598</td>\n",
       "      <td>0.16181</td>\n",
       "      <td>0.126643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190074</td>\n",
       "      <td>0.251501</td>\n",
       "      <td>0.164150</td>\n",
       "      <td>0.348711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139218</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.486705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592266</td>\n",
       "      <td>0.067240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575876</td>\n",
       "      <td>0.090140</td>\n",
       "      <td>0.146168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242476</td>\n",
       "      <td>0.342992</td>\n",
       "      <td>0.320255</td>\n",
       "      <td>0.349021</td>\n",
       "      <td>0.280934</td>\n",
       "      <td>0.455951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362476</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.568877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.132226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210107</td>\n",
       "      <td>0.661067</td>\n",
       "      <td>0.208932</td>\n",
       "      <td>0.199060</td>\n",
       "      <td>0.123822</td>\n",
       "      <td>0.683375</td>\n",
       "      <td>0.226879</td>\n",
       "      <td>0.233749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343394</td>\n",
       "      <td>0.581841</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>0.462262</td>\n",
       "      <td>0.422079</td>\n",
       "      <td>0.591579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509629</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.644886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gene_9927   gene_9928   gene_9929    gene_993   gene_9930   gene_9931  \\\n",
       "count  801.000000  801.000000  801.000000  801.000000  801.000000  801.000000   \n",
       "mean     0.133506    0.031187    0.114169    0.576883    0.167557    0.120448   \n",
       "std      0.230714    0.107527    0.167800    0.124997    0.239211    0.171600   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.513464    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.592266    0.067240    0.000000   \n",
       "75%      0.132226    0.000000    0.210107    0.661067    0.208932    0.199060   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        gene_9932   gene_9933   gene_9934   gene_9935  ...   gene_9990  \\\n",
       "count  801.000000  801.000000  801.000000  801.000000  ...  801.000000   \n",
       "mean     0.076820    0.579498    0.130505    0.181222  ...    0.270382   \n",
       "std      0.115456    0.156195    0.167667    0.162166  ...    0.183705   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      0.000000    0.480012    0.000000    0.076392  ...    0.143799   \n",
       "50%      0.000000    0.575876    0.090140    0.146168  ...    0.242476   \n",
       "75%      0.123822    0.683375    0.226879    0.233749  ...    0.343394   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        gene_9991   gene_9992   gene_9993   gene_9994   gene_9995   gene_9996  \\\n",
       "count  801.000000  801.000000  801.000000  801.000000  801.000000  801.000000   \n",
       "mean     0.336316    0.339964    0.363043    0.309524    0.467481    0.030963   \n",
       "std      0.282232    0.195718    0.162130    0.201622    0.186034    0.083459   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.190074    0.251501    0.164150    0.348711    0.000000   \n",
       "50%      0.342992    0.320255    0.349021    0.280934    0.455951    0.000000   \n",
       "75%      0.581841    0.473118    0.462262    0.422079    0.591579    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        gene_9997  gene_9998   gene_9999  \n",
       "count  801.000000  801.00000  801.000000  \n",
       "mean     0.336231    0.06967    0.561714  \n",
       "std      0.235598    0.16181    0.126643  \n",
       "min      0.000000    0.00000    0.000000  \n",
       "25%      0.139218    0.00000    0.486705  \n",
       "50%      0.362476    0.00000    0.568877  \n",
       "75%      0.509629    0.00000    0.644886  \n",
       "max      1.000000    1.00000    1.000000  \n",
       "\n",
       "[8 rows x 80 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fa018a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension Reduction done\n"
     ]
    }
   ],
   "source": [
    "# # Method 1 for dimension reduction\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# model1=RandomForestRegressor(random_state=2,max_depth=10)\n",
    "# model1.fit(data,labels)\n",
    "# print(\"Dimension Reduction done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6251872d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# features=data.columns\n",
    "# importances=model1.feature_importances_\n",
    "# indices = np.argsort(importances)[-20:]  # top 80 features\n",
    "# plt.title('Feature Importances')\n",
    "# plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "# plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "# plt.xlabel('Relative Importance')\n",
    "# plt.show()\n",
    "# selected_features=[features[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d20b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features=data.columns\n",
    "data_after_RF=data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1140169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_9927</th>\n",
       "      <th>gene_9928</th>\n",
       "      <th>gene_9929</th>\n",
       "      <th>gene_993</th>\n",
       "      <th>gene_9930</th>\n",
       "      <th>gene_9931</th>\n",
       "      <th>gene_9932</th>\n",
       "      <th>gene_9933</th>\n",
       "      <th>gene_9934</th>\n",
       "      <th>gene_9935</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_9990</th>\n",
       "      <th>gene_9991</th>\n",
       "      <th>gene_9992</th>\n",
       "      <th>gene_9993</th>\n",
       "      <th>gene_9994</th>\n",
       "      <th>gene_9995</th>\n",
       "      <th>gene_9996</th>\n",
       "      <th>gene_9997</th>\n",
       "      <th>gene_9998</th>\n",
       "      <th>gene_9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249004</td>\n",
       "      <td>0.612961</td>\n",
       "      <td>0.034693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232842</td>\n",
       "      <td>0.701605</td>\n",
       "      <td>0.201014</td>\n",
       "      <td>0.204521</td>\n",
       "      <td>0.413698</td>\n",
       "      <td>0.202251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406401</td>\n",
       "      <td>0.303412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086531</td>\n",
       "      <td>0.643644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239429</td>\n",
       "      <td>0.140823</td>\n",
       "      <td>0.512629</td>\n",
       "      <td>0.146869</td>\n",
       "      <td>0.614346</td>\n",
       "      <td>0.794487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506583</td>\n",
       "      <td>0.091617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273225</td>\n",
       "      <td>0.149860</td>\n",
       "      <td>0.383016</td>\n",
       "      <td>0.305764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.264123</td>\n",
       "      <td>0.051112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747130</td>\n",
       "      <td>0.556956</td>\n",
       "      <td>0.106505</td>\n",
       "      <td>0.110599</td>\n",
       "      <td>0.809016</td>\n",
       "      <td>0.331405</td>\n",
       "      <td>0.464986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153188</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.367076</td>\n",
       "      <td>0.147799</td>\n",
       "      <td>0.289340</td>\n",
       "      <td>0.573902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663729</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097075</td>\n",
       "      <td>0.495370</td>\n",
       "      <td>0.336588</td>\n",
       "      <td>0.172666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319222</td>\n",
       "      <td>0.571493</td>\n",
       "      <td>0.351214</td>\n",
       "      <td>0.765403</td>\n",
       "      <td>0.532738</td>\n",
       "      <td>0.780900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.202751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461057</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>0.182371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100458</td>\n",
       "      <td>0.102211</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>0.441522</td>\n",
       "      <td>0.120261</td>\n",
       "      <td>0.184402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.575914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.045279</td>\n",
       "      <td>0.094607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657807</td>\n",
       "      <td>0.092543</td>\n",
       "      <td>0.435918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340370</td>\n",
       "      <td>0.711648</td>\n",
       "      <td>0.183219</td>\n",
       "      <td>0.444543</td>\n",
       "      <td>0.254238</td>\n",
       "      <td>0.428057</td>\n",
       "      <td>0.072264</td>\n",
       "      <td>0.149630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.104974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344813</td>\n",
       "      <td>0.239239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.083580</td>\n",
       "      <td>0.562303</td>\n",
       "      <td>0.222065</td>\n",
       "      <td>0.154295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291933</td>\n",
       "      <td>0.253096</td>\n",
       "      <td>0.622239</td>\n",
       "      <td>0.349021</td>\n",
       "      <td>0.535468</td>\n",
       "      <td>0.640127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.052949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177216</td>\n",
       "      <td>0.561495</td>\n",
       "      <td>0.425556</td>\n",
       "      <td>0.198841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411080</td>\n",
       "      <td>0.737109</td>\n",
       "      <td>0.495502</td>\n",
       "      <td>0.363620</td>\n",
       "      <td>0.514074</td>\n",
       "      <td>0.830177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.157913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226736</td>\n",
       "      <td>0.409901</td>\n",
       "      <td>0.271561</td>\n",
       "      <td>0.167060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349112</td>\n",
       "      <td>0.326804</td>\n",
       "      <td>0.931625</td>\n",
       "      <td>0.911820</td>\n",
       "      <td>0.110164</td>\n",
       "      <td>0.450153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene_9927  gene_9928  gene_9929  gene_993  gene_9930  gene_9931  \\\n",
       "0     0.000000   0.000000   0.249004  0.612961   0.034693   0.000000   \n",
       "1     0.062113   0.000000   0.000000  0.406401   0.303412   0.000000   \n",
       "2     0.000000   0.000000   0.000000  0.506583   0.091617   0.000000   \n",
       "3     0.264123   0.051112   0.000000  0.747130   0.556956   0.106505   \n",
       "4     0.069681   0.000000   0.000000  0.663729   0.099398   0.000000   \n",
       "..         ...        ...        ...       ...        ...        ...   \n",
       "796   0.202751   0.000000   0.000000  0.461057   0.062487   0.182371   \n",
       "797   0.045279   0.094607   0.000000  0.657807   0.092543   0.435918   \n",
       "798   0.104974   0.000000   0.344813  0.239239   0.000000   0.145200   \n",
       "799   0.052949   0.000000   0.000000  0.455458   0.000000   0.000000   \n",
       "800   0.157913   0.000000   0.226736  0.409901   0.271561   0.167060   \n",
       "\n",
       "     gene_9932  gene_9933  gene_9934  gene_9935  ...  gene_9990  gene_9991  \\\n",
       "0     0.000000   0.339472   0.000000   0.196995  ...   0.232842   0.701605   \n",
       "1     0.086531   0.643644   0.000000   0.158414  ...   0.239429   0.140823   \n",
       "2     0.000000   0.343722   0.000000   0.205697  ...   0.243129   0.000000   \n",
       "3     0.110599   0.809016   0.331405   0.464986  ...   0.153188   0.035301   \n",
       "4     0.097075   0.495370   0.336588   0.172666  ...   0.319222   0.571493   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "796   0.000000   0.560209   0.000000   0.000000  ...   0.351077   0.000000   \n",
       "797   0.000000   0.617929   0.000000   0.144411  ...   0.340370   0.711648   \n",
       "798   0.083580   0.562303   0.222065   0.154295  ...   0.291933   0.253096   \n",
       "799   0.177216   0.561495   0.425556   0.198841  ...   0.411080   0.737109   \n",
       "800   0.000000   0.600308   0.000000   0.142498  ...   0.332425   0.000000   \n",
       "\n",
       "     gene_9992  gene_9993  gene_9994  gene_9995  gene_9996  gene_9997  \\\n",
       "0     0.201014   0.204521   0.413698   0.202251   0.000000   0.323391   \n",
       "1     0.512629   0.146869   0.614346   0.794487   0.000000   0.445629   \n",
       "2     0.273225   0.149860   0.383016   0.305764   0.000000   0.223135   \n",
       "3     0.367076   0.147799   0.289340   0.573902   0.000000   0.000000   \n",
       "4     0.351214   0.765403   0.532738   0.780900   0.000000   0.515430   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "796   0.100458   0.102211   0.678079   0.441522   0.120261   0.184402   \n",
       "797   0.183219   0.444543   0.254238   0.428057   0.072264   0.149630   \n",
       "798   0.622239   0.349021   0.535468   0.640127   0.000000   0.564047   \n",
       "799   0.495502   0.363620   0.514074   0.830177   0.000000   0.366916   \n",
       "800   0.349112   0.326804   0.931625   0.911820   0.110164   0.450153   \n",
       "\n",
       "     gene_9998  gene_9999  \n",
       "0          0.0   0.464955  \n",
       "1          0.0   0.456855  \n",
       "2          0.0   0.160535  \n",
       "3          0.0   0.457369  \n",
       "4          0.0   0.744697  \n",
       "..         ...        ...  \n",
       "796        0.0   0.575914  \n",
       "797        0.0   0.587541  \n",
       "798        0.0   0.689699  \n",
       "799        0.0   0.804147  \n",
       "800        0.0   0.704914  \n",
       "\n",
       "[801 rows x 80 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_after_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5da024e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      2\n",
       "4      0\n",
       "      ..\n",
       "796    1\n",
       "797    0\n",
       "798    1\n",
       "799    0\n",
       "800    1\n",
       "Name: label, Length: 801, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94959865",
   "metadata": {},
   "source": [
    "<h1 > Halt and Stop </h1>\n",
    "<h2> PCA Code </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1288828d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.629531</td>\n",
       "      <td>14.856823</td>\n",
       "      <td>10.593409</td>\n",
       "      <td>-3.781079</td>\n",
       "      <td>-0.230631</td>\n",
       "      <td>-2.629830</td>\n",
       "      <td>2.825996</td>\n",
       "      <td>-8.828905</td>\n",
       "      <td>-3.269102</td>\n",
       "      <td>-6.578480</td>\n",
       "      <td>2.159592</td>\n",
       "      <td>1.837202</td>\n",
       "      <td>-1.987490</td>\n",
       "      <td>1.322127</td>\n",
       "      <td>2.970779</td>\n",
       "      <td>-3.654699</td>\n",
       "      <td>2.091649</td>\n",
       "      <td>-3.082109</td>\n",
       "      <td>0.733009</td>\n",
       "      <td>-0.820087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.315133</td>\n",
       "      <td>4.921955</td>\n",
       "      <td>-3.995595</td>\n",
       "      <td>-2.255632</td>\n",
       "      <td>-0.461161</td>\n",
       "      <td>0.916194</td>\n",
       "      <td>1.667741</td>\n",
       "      <td>-3.197429</td>\n",
       "      <td>1.044379</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.168932</td>\n",
       "      <td>-0.695841</td>\n",
       "      <td>-1.567962</td>\n",
       "      <td>0.494077</td>\n",
       "      <td>-0.723823</td>\n",
       "      <td>-0.442762</td>\n",
       "      <td>1.914127</td>\n",
       "      <td>2.452142</td>\n",
       "      <td>2.941270</td>\n",
       "      <td>-0.875028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.155627</td>\n",
       "      <td>2.154239</td>\n",
       "      <td>-5.819888</td>\n",
       "      <td>-1.102799</td>\n",
       "      <td>0.287754</td>\n",
       "      <td>1.054957</td>\n",
       "      <td>-0.567482</td>\n",
       "      <td>-2.257072</td>\n",
       "      <td>-1.038818</td>\n",
       "      <td>-1.656368</td>\n",
       "      <td>-0.147627</td>\n",
       "      <td>-0.803911</td>\n",
       "      <td>-0.978908</td>\n",
       "      <td>-1.965637</td>\n",
       "      <td>-0.601632</td>\n",
       "      <td>-1.967115</td>\n",
       "      <td>-2.640024</td>\n",
       "      <td>2.022526</td>\n",
       "      <td>2.801107</td>\n",
       "      <td>-0.959965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.103288</td>\n",
       "      <td>3.767917</td>\n",
       "      <td>-6.018159</td>\n",
       "      <td>-1.677049</td>\n",
       "      <td>1.064371</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>-1.510585</td>\n",
       "      <td>-1.111558</td>\n",
       "      <td>-1.349424</td>\n",
       "      <td>-2.358492</td>\n",
       "      <td>0.466362</td>\n",
       "      <td>-1.070167</td>\n",
       "      <td>0.433423</td>\n",
       "      <td>-2.167386</td>\n",
       "      <td>-0.530678</td>\n",
       "      <td>-2.469406</td>\n",
       "      <td>-3.085323</td>\n",
       "      <td>-0.314081</td>\n",
       "      <td>0.525884</td>\n",
       "      <td>-0.751699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.893014</td>\n",
       "      <td>6.439557</td>\n",
       "      <td>-5.857893</td>\n",
       "      <td>-1.931942</td>\n",
       "      <td>0.319152</td>\n",
       "      <td>-0.173189</td>\n",
       "      <td>-0.837526</td>\n",
       "      <td>-1.445935</td>\n",
       "      <td>0.938064</td>\n",
       "      <td>-0.741610</td>\n",
       "      <td>-1.252487</td>\n",
       "      <td>0.630344</td>\n",
       "      <td>-1.756081</td>\n",
       "      <td>-1.811645</td>\n",
       "      <td>0.272141</td>\n",
       "      <td>-1.653960</td>\n",
       "      <td>-1.236539</td>\n",
       "      <td>-0.055979</td>\n",
       "      <td>0.671251</td>\n",
       "      <td>-2.306505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>-15.346321</td>\n",
       "      <td>-5.223540</td>\n",
       "      <td>2.066638</td>\n",
       "      <td>-0.071040</td>\n",
       "      <td>-2.737702</td>\n",
       "      <td>2.245572</td>\n",
       "      <td>-2.540565</td>\n",
       "      <td>-2.358935</td>\n",
       "      <td>-0.237690</td>\n",
       "      <td>-1.986813</td>\n",
       "      <td>1.721676</td>\n",
       "      <td>0.451884</td>\n",
       "      <td>0.742498</td>\n",
       "      <td>-0.463987</td>\n",
       "      <td>4.093653</td>\n",
       "      <td>4.451495</td>\n",
       "      <td>-1.226662</td>\n",
       "      <td>-5.124464</td>\n",
       "      <td>2.369892</td>\n",
       "      <td>2.796131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>-15.632898</td>\n",
       "      <td>-7.127824</td>\n",
       "      <td>2.817008</td>\n",
       "      <td>0.017201</td>\n",
       "      <td>-2.730833</td>\n",
       "      <td>2.092721</td>\n",
       "      <td>-3.115867</td>\n",
       "      <td>-3.415086</td>\n",
       "      <td>-1.001908</td>\n",
       "      <td>-2.261312</td>\n",
       "      <td>1.836727</td>\n",
       "      <td>0.698259</td>\n",
       "      <td>0.570752</td>\n",
       "      <td>-0.425441</td>\n",
       "      <td>4.355570</td>\n",
       "      <td>5.076866</td>\n",
       "      <td>-2.319139</td>\n",
       "      <td>-4.613177</td>\n",
       "      <td>3.123821</td>\n",
       "      <td>1.958682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>-17.016423</td>\n",
       "      <td>-9.349355</td>\n",
       "      <td>5.325734</td>\n",
       "      <td>1.912351</td>\n",
       "      <td>-1.780125</td>\n",
       "      <td>1.598338</td>\n",
       "      <td>-3.942679</td>\n",
       "      <td>-2.457444</td>\n",
       "      <td>-1.664441</td>\n",
       "      <td>1.860920</td>\n",
       "      <td>0.076592</td>\n",
       "      <td>1.036340</td>\n",
       "      <td>-5.423483</td>\n",
       "      <td>-1.701017</td>\n",
       "      <td>4.847681</td>\n",
       "      <td>2.904304</td>\n",
       "      <td>-1.793181</td>\n",
       "      <td>-3.872349</td>\n",
       "      <td>1.418040</td>\n",
       "      <td>0.675944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4250</th>\n",
       "      <td>-17.054935</td>\n",
       "      <td>-8.611769</td>\n",
       "      <td>3.950561</td>\n",
       "      <td>1.225732</td>\n",
       "      <td>0.202216</td>\n",
       "      <td>2.609193</td>\n",
       "      <td>-3.498617</td>\n",
       "      <td>-0.149453</td>\n",
       "      <td>-2.515303</td>\n",
       "      <td>-0.557511</td>\n",
       "      <td>1.498262</td>\n",
       "      <td>0.026294</td>\n",
       "      <td>-3.384069</td>\n",
       "      <td>-3.548249</td>\n",
       "      <td>3.816402</td>\n",
       "      <td>2.331627</td>\n",
       "      <td>-2.298082</td>\n",
       "      <td>-3.585890</td>\n",
       "      <td>-0.505159</td>\n",
       "      <td>1.327229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>-16.708425</td>\n",
       "      <td>-10.328057</td>\n",
       "      <td>4.876636</td>\n",
       "      <td>0.959383</td>\n",
       "      <td>-3.124137</td>\n",
       "      <td>1.836876</td>\n",
       "      <td>-3.873189</td>\n",
       "      <td>-2.402532</td>\n",
       "      <td>-1.433123</td>\n",
       "      <td>-0.705269</td>\n",
       "      <td>2.633819</td>\n",
       "      <td>1.115383</td>\n",
       "      <td>-3.397099</td>\n",
       "      <td>-3.938887</td>\n",
       "      <td>3.231070</td>\n",
       "      <td>3.083693</td>\n",
       "      <td>-0.378234</td>\n",
       "      <td>-1.364739</td>\n",
       "      <td>0.576016</td>\n",
       "      <td>-1.010143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4252 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2         3         4         5         6   \\\n",
       "0     17.629531  14.856823  10.593409 -3.781079 -0.230631 -2.629830  2.825996   \n",
       "1      8.315133   4.921955  -3.995595 -2.255632 -0.461161  0.916194  1.667741   \n",
       "2      5.155627   2.154239  -5.819888 -1.102799  0.287754  1.054957 -0.567482   \n",
       "3      3.103288   3.767917  -6.018159 -1.677049  1.064371  0.691963 -1.510585   \n",
       "4      1.893014   6.439557  -5.857893 -1.931942  0.319152 -0.173189 -0.837526   \n",
       "...         ...        ...        ...       ...       ...       ...       ...   \n",
       "4247 -15.346321  -5.223540   2.066638 -0.071040 -2.737702  2.245572 -2.540565   \n",
       "4248 -15.632898  -7.127824   2.817008  0.017201 -2.730833  2.092721 -3.115867   \n",
       "4249 -17.016423  -9.349355   5.325734  1.912351 -1.780125  1.598338 -3.942679   \n",
       "4250 -17.054935  -8.611769   3.950561  1.225732  0.202216  2.609193 -3.498617   \n",
       "4251 -16.708425 -10.328057   4.876636  0.959383 -3.124137  1.836876 -3.873189   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0    -8.828905 -3.269102 -6.578480  2.159592  1.837202 -1.987490  1.322127   \n",
       "1    -3.197429  1.044379  0.097800  0.168932 -0.695841 -1.567962  0.494077   \n",
       "2    -2.257072 -1.038818 -1.656368 -0.147627 -0.803911 -0.978908 -1.965637   \n",
       "3    -1.111558 -1.349424 -2.358492  0.466362 -1.070167  0.433423 -2.167386   \n",
       "4    -1.445935  0.938064 -0.741610 -1.252487  0.630344 -1.756081 -1.811645   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4247 -2.358935 -0.237690 -1.986813  1.721676  0.451884  0.742498 -0.463987   \n",
       "4248 -3.415086 -1.001908 -2.261312  1.836727  0.698259  0.570752 -0.425441   \n",
       "4249 -2.457444 -1.664441  1.860920  0.076592  1.036340 -5.423483 -1.701017   \n",
       "4250 -0.149453 -2.515303 -0.557511  1.498262  0.026294 -3.384069 -3.548249   \n",
       "4251 -2.402532 -1.433123 -0.705269  2.633819  1.115383 -3.397099 -3.938887   \n",
       "\n",
       "            14        15        16        17        18        19  \n",
       "0     2.970779 -3.654699  2.091649 -3.082109  0.733009 -0.820087  \n",
       "1    -0.723823 -0.442762  1.914127  2.452142  2.941270 -0.875028  \n",
       "2    -0.601632 -1.967115 -2.640024  2.022526  2.801107 -0.959965  \n",
       "3    -0.530678 -2.469406 -3.085323 -0.314081  0.525884 -0.751699  \n",
       "4     0.272141 -1.653960 -1.236539 -0.055979  0.671251 -2.306505  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "4247  4.093653  4.451495 -1.226662 -5.124464  2.369892  2.796131  \n",
       "4248  4.355570  5.076866 -2.319139 -4.613177  3.123821  1.958682  \n",
       "4249  4.847681  2.904304 -1.793181 -3.872349  1.418040  0.675944  \n",
       "4250  3.816402  2.331627 -2.298082 -3.585890 -0.505159  1.327229  \n",
       "4251  3.231070  3.083693 -0.378234 -1.364739  0.576016 -1.010143  \n",
       "\n",
       "[4252 rows x 20 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_1 = PCA(n_components=20)\n",
    "principalComponents = pca_1.fit_transform(X_train)\n",
    "data_after_RF=pd.DataFrame(principalComponents)\n",
    "data_after_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4258a1eb",
   "metadata": {},
   "source": [
    "<h2> PCA STOP </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64dfddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting Percentages are: [5, 10, 15, 20, 25]\n",
      "Splitting Position are: [0, 40, 120, 240, 400, 600]\n"
     ]
    }
   ],
   "source": [
    "# Defining Splitter for the dataset (Common for all)\n",
    "def splitter(len_array,lower_bound, incrementor, start_idx):\n",
    "    final=0\n",
    "    per=[]\n",
    "    sp=[start_idx]\n",
    "    for i in range(lower_bound,100,incrementor):\n",
    "        if final+i>100:\n",
    "            break\n",
    "        per.append(i)\n",
    "        final+=i\n",
    "    for i in per:\n",
    "        len_of_data=round((i/100)*len_array)\n",
    "        sp.append(sp[-1]+len_of_data)\n",
    "    return per,sp\n",
    "\n",
    "lower_bound=5\n",
    "incrementor=5\n",
    "start_idx=0\n",
    "\n",
    "        \n",
    "spliting_percentage, spliting_position=splitter(len(data),lower_bound,incrementor,start_idx)\n",
    "print(\"Splitting Percentages are: {}\".format(spliting_percentage))\n",
    "print(\"Splitting Position are: {}\".format(spliting_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ced02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_experiment=data_after_RF.copy(deep=True)\n",
    "labels_for_experiment=labels.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2339956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_9927</th>\n",
       "      <th>gene_9928</th>\n",
       "      <th>gene_9929</th>\n",
       "      <th>gene_993</th>\n",
       "      <th>gene_9930</th>\n",
       "      <th>gene_9931</th>\n",
       "      <th>gene_9932</th>\n",
       "      <th>gene_9933</th>\n",
       "      <th>gene_9934</th>\n",
       "      <th>gene_9935</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_9990</th>\n",
       "      <th>gene_9991</th>\n",
       "      <th>gene_9992</th>\n",
       "      <th>gene_9993</th>\n",
       "      <th>gene_9994</th>\n",
       "      <th>gene_9995</th>\n",
       "      <th>gene_9996</th>\n",
       "      <th>gene_9997</th>\n",
       "      <th>gene_9998</th>\n",
       "      <th>gene_9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249004</td>\n",
       "      <td>0.612961</td>\n",
       "      <td>0.034693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232842</td>\n",
       "      <td>0.701605</td>\n",
       "      <td>0.201014</td>\n",
       "      <td>0.204521</td>\n",
       "      <td>0.413698</td>\n",
       "      <td>0.202251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406401</td>\n",
       "      <td>0.303412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086531</td>\n",
       "      <td>0.643644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239429</td>\n",
       "      <td>0.140823</td>\n",
       "      <td>0.512629</td>\n",
       "      <td>0.146869</td>\n",
       "      <td>0.614346</td>\n",
       "      <td>0.794487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506583</td>\n",
       "      <td>0.091617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273225</td>\n",
       "      <td>0.149860</td>\n",
       "      <td>0.383016</td>\n",
       "      <td>0.305764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.264123</td>\n",
       "      <td>0.051112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747130</td>\n",
       "      <td>0.556956</td>\n",
       "      <td>0.106505</td>\n",
       "      <td>0.110599</td>\n",
       "      <td>0.809016</td>\n",
       "      <td>0.331405</td>\n",
       "      <td>0.464986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153188</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.367076</td>\n",
       "      <td>0.147799</td>\n",
       "      <td>0.289340</td>\n",
       "      <td>0.573902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663729</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097075</td>\n",
       "      <td>0.495370</td>\n",
       "      <td>0.336588</td>\n",
       "      <td>0.172666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319222</td>\n",
       "      <td>0.571493</td>\n",
       "      <td>0.351214</td>\n",
       "      <td>0.765403</td>\n",
       "      <td>0.532738</td>\n",
       "      <td>0.780900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.202751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461057</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>0.182371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100458</td>\n",
       "      <td>0.102211</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>0.441522</td>\n",
       "      <td>0.120261</td>\n",
       "      <td>0.184402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.575914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.045279</td>\n",
       "      <td>0.094607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657807</td>\n",
       "      <td>0.092543</td>\n",
       "      <td>0.435918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340370</td>\n",
       "      <td>0.711648</td>\n",
       "      <td>0.183219</td>\n",
       "      <td>0.444543</td>\n",
       "      <td>0.254238</td>\n",
       "      <td>0.428057</td>\n",
       "      <td>0.072264</td>\n",
       "      <td>0.149630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.104974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344813</td>\n",
       "      <td>0.239239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.083580</td>\n",
       "      <td>0.562303</td>\n",
       "      <td>0.222065</td>\n",
       "      <td>0.154295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291933</td>\n",
       "      <td>0.253096</td>\n",
       "      <td>0.622239</td>\n",
       "      <td>0.349021</td>\n",
       "      <td>0.535468</td>\n",
       "      <td>0.640127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.052949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177216</td>\n",
       "      <td>0.561495</td>\n",
       "      <td>0.425556</td>\n",
       "      <td>0.198841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411080</td>\n",
       "      <td>0.737109</td>\n",
       "      <td>0.495502</td>\n",
       "      <td>0.363620</td>\n",
       "      <td>0.514074</td>\n",
       "      <td>0.830177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.157913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226736</td>\n",
       "      <td>0.409901</td>\n",
       "      <td>0.271561</td>\n",
       "      <td>0.167060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349112</td>\n",
       "      <td>0.326804</td>\n",
       "      <td>0.931625</td>\n",
       "      <td>0.911820</td>\n",
       "      <td>0.110164</td>\n",
       "      <td>0.450153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene_9927  gene_9928  gene_9929  gene_993  gene_9930  gene_9931  \\\n",
       "0     0.000000   0.000000   0.249004  0.612961   0.034693   0.000000   \n",
       "1     0.062113   0.000000   0.000000  0.406401   0.303412   0.000000   \n",
       "2     0.000000   0.000000   0.000000  0.506583   0.091617   0.000000   \n",
       "3     0.264123   0.051112   0.000000  0.747130   0.556956   0.106505   \n",
       "4     0.069681   0.000000   0.000000  0.663729   0.099398   0.000000   \n",
       "..         ...        ...        ...       ...        ...        ...   \n",
       "796   0.202751   0.000000   0.000000  0.461057   0.062487   0.182371   \n",
       "797   0.045279   0.094607   0.000000  0.657807   0.092543   0.435918   \n",
       "798   0.104974   0.000000   0.344813  0.239239   0.000000   0.145200   \n",
       "799   0.052949   0.000000   0.000000  0.455458   0.000000   0.000000   \n",
       "800   0.157913   0.000000   0.226736  0.409901   0.271561   0.167060   \n",
       "\n",
       "     gene_9932  gene_9933  gene_9934  gene_9935  ...  gene_9990  gene_9991  \\\n",
       "0     0.000000   0.339472   0.000000   0.196995  ...   0.232842   0.701605   \n",
       "1     0.086531   0.643644   0.000000   0.158414  ...   0.239429   0.140823   \n",
       "2     0.000000   0.343722   0.000000   0.205697  ...   0.243129   0.000000   \n",
       "3     0.110599   0.809016   0.331405   0.464986  ...   0.153188   0.035301   \n",
       "4     0.097075   0.495370   0.336588   0.172666  ...   0.319222   0.571493   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "796   0.000000   0.560209   0.000000   0.000000  ...   0.351077   0.000000   \n",
       "797   0.000000   0.617929   0.000000   0.144411  ...   0.340370   0.711648   \n",
       "798   0.083580   0.562303   0.222065   0.154295  ...   0.291933   0.253096   \n",
       "799   0.177216   0.561495   0.425556   0.198841  ...   0.411080   0.737109   \n",
       "800   0.000000   0.600308   0.000000   0.142498  ...   0.332425   0.000000   \n",
       "\n",
       "     gene_9992  gene_9993  gene_9994  gene_9995  gene_9996  gene_9997  \\\n",
       "0     0.201014   0.204521   0.413698   0.202251   0.000000   0.323391   \n",
       "1     0.512629   0.146869   0.614346   0.794487   0.000000   0.445629   \n",
       "2     0.273225   0.149860   0.383016   0.305764   0.000000   0.223135   \n",
       "3     0.367076   0.147799   0.289340   0.573902   0.000000   0.000000   \n",
       "4     0.351214   0.765403   0.532738   0.780900   0.000000   0.515430   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "796   0.100458   0.102211   0.678079   0.441522   0.120261   0.184402   \n",
       "797   0.183219   0.444543   0.254238   0.428057   0.072264   0.149630   \n",
       "798   0.622239   0.349021   0.535468   0.640127   0.000000   0.564047   \n",
       "799   0.495502   0.363620   0.514074   0.830177   0.000000   0.366916   \n",
       "800   0.349112   0.326804   0.931625   0.911820   0.110164   0.450153   \n",
       "\n",
       "     gene_9998  gene_9999  \n",
       "0          0.0   0.464955  \n",
       "1          0.0   0.456855  \n",
       "2          0.0   0.160535  \n",
       "3          0.0   0.457369  \n",
       "4          0.0   0.744697  \n",
       "..         ...        ...  \n",
       "796        0.0   0.575914  \n",
       "797        0.0   0.587541  \n",
       "798        0.0   0.689699  \n",
       "799        0.0   0.804147  \n",
       "800        0.0   0.704914  \n",
       "\n",
       "[801 rows x 80 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_after_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13c87ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      2\n",
       "4      0\n",
       "      ..\n",
       "796    1\n",
       "797    0\n",
       "798    1\n",
       "799    0\n",
       "800    1\n",
       "Name: label, Length: 801, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_for_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b27d89c",
   "metadata": {},
   "source": [
    "# Apply ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aff76ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.2\n",
      "Best: 0.000000 using {'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "[[68  0  0  2  0]\n",
      " [ 0  9  0  1  0]\n",
      " [ 0  0 29  0  0]\n",
      " [ 2  0  0 29  0]\n",
      " [ 0  0  0  0 21]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        70\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       1.00      1.00      1.00        29\n",
      "           3       0.91      0.94      0.92        31\n",
      "           4       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.98      0.96      0.97       161\n",
      "weighted avg       0.97      0.97      0.97       161\n",
      "\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SImple Algorithm\n",
    "# splitting dataset into training and testing part\n",
    "test_data_ratio=[0.2]\n",
    "for i in test_data_ratio:\n",
    "    print(\"******************Start of iteration******************\\n\")\n",
    "    print(\"For ratio \",i)\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data_after_RF,labels,test_size=i,shuffle=True)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    solvers = [\"lbfgs\",\"liblinear\"]\n",
    "    penalty = ['l2']\n",
    "    c_values = [5]\n",
    "    # define grid search\n",
    "    grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1',error_score=0,)\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "#     print(\"Training set score for logreg_model: %f\" % grid_search.score(X_train , y_train))\n",
    "#     print(\"Testing  set score for logreg_model: %f\" % grid_search.score(X_test  , y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b46c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "Splitting percentage is 5\n",
      "Shape of training input X_train: (40, 80)\n",
      "Shape of testing input X_test: (40, 80)\n",
      "Shape of training output Y_train: (40,)\n",
      "Shape of testing output Y_test: (40, 1)\n",
      "Best: 0.000000 using {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "[[16  0  0  0  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 1  0  9  0  1]\n",
      " [ 5  0  0  3  1]\n",
      " [ 0  0  0  0  2]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84        16\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.82      0.90        11\n",
      "           3       1.00      0.33      0.50         9\n",
      "           4       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.80        40\n",
      "   macro avg       0.85      0.83      0.78        40\n",
      "weighted avg       0.87      0.80      0.78        40\n",
      "\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 10\n",
      "Shape of training input X_train: (80, 80)\n",
      "Shape of testing input X_test: (80, 80)\n",
      "Shape of training output Y_train: (80,)\n",
      "Shape of testing output Y_test: (80, 1)\n",
      "Best: 0.000000 using {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "[[33  0  0  1  0]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0  0 19  1  0]\n",
      " [ 3  0  0  5  0]\n",
      " [ 0  0  0  0 17]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        34\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       1.00      0.95      0.97        20\n",
      "           3       0.71      0.62      0.67         8\n",
      "           4       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.93      0.91      0.92        80\n",
      "weighted avg       0.94      0.94      0.94        80\n",
      "\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 15\n",
      "Shape of training input X_train: (120, 80)\n",
      "Shape of testing input X_test: (120, 80)\n",
      "Shape of training output Y_train: (120,)\n",
      "Shape of testing output Y_test: (120, 1)\n",
      "Best: 0.000000 using {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "[[43  0  0  0  0]\n",
      " [ 0 11  0  0  0]\n",
      " [ 1  0 25  0  1]\n",
      " [ 4  3  0 15  1]\n",
      " [ 0  0  0  0 16]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        43\n",
      "           1       0.79      1.00      0.88        11\n",
      "           2       1.00      0.93      0.96        27\n",
      "           3       1.00      0.65      0.79        23\n",
      "           4       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.92       120\n",
      "   macro avg       0.91      0.92      0.90       120\n",
      "weighted avg       0.93      0.92      0.91       120\n",
      "\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 20\n",
      "Shape of training input X_train: (160, 80)\n",
      "Shape of testing input X_test: (160, 80)\n",
      "Shape of training output Y_train: (160,)\n",
      "Shape of testing output Y_test: (160, 1)\n",
      "Best: 0.000000 using {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "[[58  0  0  2  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0  0 28  0  0]\n",
      " [ 2  0  0 28  0]\n",
      " [ 0  0  0  0 21]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        60\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00        28\n",
      "           3       0.93      0.93      0.93        30\n",
      "           4       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.98      0.98      0.98       160\n",
      "weighted avg       0.97      0.97      0.97       160\n",
      "\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 25\n",
      "Shape of training input X_train: (200, 80)\n",
      "Shape of testing input X_test: (200, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best: 0.000000 using {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "[[75  0  0  0  0]\n",
      " [ 0 19  0  0  0]\n",
      " [ 2  0 28  0  0]\n",
      " [ 1  0  0 33  0]\n",
      " [ 1  0  0  0 41]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        75\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       1.00      0.93      0.97        30\n",
      "           3       1.00      0.97      0.99        34\n",
      "           4       1.00      0.98      0.99        42\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.99      0.98      0.98       200\n",
      "weighted avg       0.98      0.98      0.98       200\n",
      "\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(spliting_position)-1):\n",
    "    print(\"******************Start of iteration******************\")\n",
    "    print(\"Splitting percentage is {}\".format(spliting_percentage[i]))\n",
    "    \n",
    "    X_train=pd.DataFrame(data_for_experiment.iloc[spliting_position[i]:spliting_position[i+1],:])\n",
    "    Y_train=labels_for_experiment.iloc[spliting_position[i]:spliting_position[i+1]]\n",
    "    X_test=data_for_experiment.drop(X_train.index, axis=0).sample(len(X_train))\n",
    "    Y_test=np.array(pd.DataFrame(labels_for_experiment,index=X_test.index))\n",
    "    \n",
    "    print(\"Shape of training input X_train: {}\".format(X_train.shape))\n",
    "    print(\"Shape of testing input X_test: {}\".format(X_test.shape))\n",
    "    print(\"Shape of training output Y_train: {}\".format(Y_train.shape))\n",
    "    print(\"Shape of testing output Y_test: {}\".format(Y_test.shape))\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    solvers = [\"lbfgs\",\"liblinear\"]\n",
    "    penalty = ['l2','l1']\n",
    "    c_values = [10]\n",
    "    # define grid search\n",
    "    grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=2, cv=cv, scoring='f1',error_score=0,)\n",
    "    grid_result = grid_search.fit(X_train, Y_train)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    Y_pred = grid_search.predict(X_test)\n",
    "    print(confusion_matrix(Y_test,Y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170ccd98",
   "metadata": {},
   "source": [
    "# ****KNN Classifer ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "480dacab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.2\n",
      "Best score for training data: 0.93125 \n",
      "\n",
      "Best #neighbors: 3 \n",
      "\n",
      "Best weights: uniform \n",
      "\n",
      "Best leaf_size: 4 \n",
      "\n",
      "Best algorithm: auto \n",
      "\n",
      "[[68  0  0  3  0]\n",
      " [ 0 10  0  0  0]\n",
      " [ 2  0 27  0  0]\n",
      " [ 5  1  0 21  0]\n",
      " [ 0  0  0  0 24]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        71\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        29\n",
      "           3       0.88      0.78      0.82        27\n",
      "           4       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.93       161\n",
      "   macro avg       0.94      0.93      0.93       161\n",
      "weighted avg       0.93      0.93      0.93       161\n",
      "\n",
      "Training set score for knn_model: 0.967187\n",
      "Testing  set score for knn_model: 0.931677\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "test_data_ratio=[0.2]\n",
    "for i in test_data_ratio:\n",
    "    print(\"******************Start of iteration******************\\n\")\n",
    "    print(\"For ratio \",i)\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data_after_RF,labels,test_size=i,shuffle=True)\n",
    "    model = KNeighborsClassifier()\n",
    "    params_grid = [{'n_neighbors': [2,3,4], 'weights' :['uniform'],'leaf_size':[4,5,6,7,8,9],'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}]\n",
    "    knn_model = GridSearchCV(model, params_grid, cv=5)\n",
    "    knn_model.fit(X_train,y_train)\n",
    "    print('Best score for training data:', knn_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best #neighbors:',knn_model.best_estimator_.n_neighbors,\"\\n\") \n",
    "    print('Best weights:',knn_model.best_estimator_.weights,\"\\n\")\n",
    "    print('Best leaf_size:',knn_model.best_estimator_.leaf_size,\"\\n\")\n",
    "    print('Best algorithm:',knn_model.best_estimator_.algorithm,\"\\n\")\n",
    "    final_model = knn_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training set score for knn_model: %f\" % final_model.score(X_train , y_train))\n",
    "    print(\"Testing  set score for knn_model: %f\" % final_model.score(X_test  , y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acc79f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "Splitting percentage is 5\n",
      "Shape of training input X_train: (40, 80)\n",
      "Shape of testing input X_test: (40, 80)\n",
      "Shape of training output Y_train: (40,)\n",
      "Shape of testing output Y_test: (40, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luhar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.925 \n",
      "\n",
      "Best #neighbors: 2 \n",
      "\n",
      "Best weights: uniform \n",
      "\n",
      "Best leaf_size: 4 \n",
      "\n",
      "Best algorithm: auto \n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 0  5  0  0  0]\n",
      " [ 1  1  7  0  0]\n",
      " [ 0  2  0  2  2]\n",
      " [ 0  0  0  0  7]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        71\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        29\n",
      "           3       0.88      0.78      0.82        27\n",
      "           4       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.93       161\n",
      "   macro avg       0.94      0.93      0.93       161\n",
      "weighted avg       0.93      0.93      0.93       161\n",
      "\n",
      "Training set score for knn_model: 0.950000\n",
      "Testing  set score for knn_model: 0.850000\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 10\n",
      "Shape of training input X_train: (80, 80)\n",
      "Shape of testing input X_test: (80, 80)\n",
      "Shape of training output Y_train: (80,)\n",
      "Shape of testing output Y_test: (80, 1)\n",
      "Best score for training data: 0.8875 \n",
      "\n",
      "Best #neighbors: 3 \n",
      "\n",
      "Best weights: uniform \n",
      "\n",
      "Best leaf_size: 4 \n",
      "\n",
      "Best algorithm: auto \n",
      "\n",
      "[[30  0  0  0  0]\n",
      " [ 0 11  0  0  0]\n",
      " [ 1  0 11  0  0]\n",
      " [11  0  0  2  0]\n",
      " [ 1  0  0  0 13]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        71\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        29\n",
      "           3       0.88      0.78      0.82        27\n",
      "           4       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.93       161\n",
      "   macro avg       0.94      0.93      0.93       161\n",
      "weighted avg       0.93      0.93      0.93       161\n",
      "\n",
      "Training set score for knn_model: 0.950000\n",
      "Testing  set score for knn_model: 0.837500\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 15\n",
      "Shape of training input X_train: (120, 80)\n",
      "Shape of testing input X_test: (120, 80)\n",
      "Shape of training output Y_train: (120,)\n",
      "Shape of testing output Y_test: (120, 1)\n",
      "Best score for training data: 0.9166666666666666 \n",
      "\n",
      "Best #neighbors: 3 \n",
      "\n",
      "Best weights: uniform \n",
      "\n",
      "Best leaf_size: 4 \n",
      "\n",
      "Best algorithm: auto \n",
      "\n",
      "[[39  0  0  0  1]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 5  1  0 13  0]\n",
      " [ 0  0  0  0 23]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        71\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        29\n",
      "           3       0.88      0.78      0.82        27\n",
      "           4       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.93       161\n",
      "   macro avg       0.94      0.93      0.93       161\n",
      "weighted avg       0.93      0.93      0.93       161\n",
      "\n",
      "Training set score for knn_model: 0.933333\n",
      "Testing  set score for knn_model: 0.941667\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 20\n",
      "Shape of training input X_train: (160, 80)\n",
      "Shape of testing input X_test: (160, 80)\n",
      "Shape of training output Y_train: (160,)\n",
      "Shape of testing output Y_test: (160, 1)\n",
      "Best score for training data: 0.89375 \n",
      "\n",
      "Best #neighbors: 4 \n",
      "\n",
      "Best weights: uniform \n",
      "\n",
      "Best leaf_size: 4 \n",
      "\n",
      "Best algorithm: auto \n",
      "\n",
      "[[52  0  0  1  0]\n",
      " [ 0 22  0  0  0]\n",
      " [ 0  0 27  0  3]\n",
      " [ 9  0  0 15  1]\n",
      " [ 0  0  0  0 30]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        71\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        29\n",
      "           3       0.88      0.78      0.82        27\n",
      "           4       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.93       161\n",
      "   macro avg       0.94      0.93      0.93       161\n",
      "weighted avg       0.93      0.93      0.93       161\n",
      "\n",
      "Training set score for knn_model: 0.925000\n",
      "Testing  set score for knn_model: 0.912500\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 25\n",
      "Shape of training input X_train: (200, 80)\n",
      "Shape of testing input X_test: (200, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.8800000000000001 \n",
      "\n",
      "Best #neighbors: 3 \n",
      "\n",
      "Best weights: uniform \n",
      "\n",
      "Best leaf_size: 4 \n",
      "\n",
      "Best algorithm: auto \n",
      "\n",
      "[[76  0  0  2  0]\n",
      " [ 0 17  0  0  0]\n",
      " [ 2  0 34  0  2]\n",
      " [17  1  0 17  0]\n",
      " [ 0  0  0  0 32]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        71\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        29\n",
      "           3       0.88      0.78      0.82        27\n",
      "           4       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.93       161\n",
      "   macro avg       0.94      0.93      0.93       161\n",
      "weighted avg       0.93      0.93      0.93       161\n",
      "\n",
      "Training set score for knn_model: 0.945000\n",
      "Testing  set score for knn_model: 0.880000\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "for i in range(len(spliting_position)-1):\n",
    "    print(\"******************Start of iteration******************\")\n",
    "    print(\"Splitting percentage is {}\".format(spliting_percentage[i]))\n",
    "    \n",
    "    X_train=pd.DataFrame(data_for_experiment.iloc[spliting_position[i]:spliting_position[i+1],:])\n",
    "    Y_train=labels_for_experiment.iloc[spliting_position[i]:spliting_position[i+1]]\n",
    "    X_test=data_for_experiment.drop(X_train.index, axis=0).sample(len(X_train))\n",
    "    Y_test=np.array(pd.DataFrame(labels_for_experiment,index=X_test.index))\n",
    "    \n",
    "    print(\"Shape of training input X_train: {}\".format(X_train.shape))\n",
    "    print(\"Shape of testing input X_test: {}\".format(X_test.shape))\n",
    "    print(\"Shape of training output Y_train: {}\".format(Y_train.shape))\n",
    "    print(\"Shape of testing output Y_test: {}\".format(Y_test.shape))\n",
    "    model = KNeighborsClassifier()\n",
    "    params_grid = [{'n_neighbors': [2,3,4], 'weights' :['uniform'],'leaf_size':[4,5,6,7,8,9],'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}]\n",
    "    knn_model = GridSearchCV(model, params_grid, cv=5)\n",
    "    knn_model.fit(X_train,Y_train)\n",
    "    print('Best score for training data:', knn_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best #neighbors:',knn_model.best_estimator_.n_neighbors,\"\\n\") \n",
    "    print('Best weights:',knn_model.best_estimator_.weights,\"\\n\")\n",
    "    print('Best leaf_size:',knn_model.best_estimator_.leaf_size,\"\\n\")\n",
    "    print('Best algorithm:',knn_model.best_estimator_.algorithm,\"\\n\")\n",
    "    final_model = knn_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    Y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(Y_test,Y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training set score for knn_model: %f\" % final_model.score(X_train , Y_train))\n",
    "    print(\"Testing  set score for knn_model: %f\" % final_model.score(X_test  , Y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5541e508",
   "metadata": {},
   "source": [
    "# ** Support Vector Machine **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c82f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.2\n",
      "Best score for training data: 0.9625217556637855 \n",
      "\n",
      "Best C: 2 \n",
      "\n",
      "Best Kernel: linear \n",
      "\n",
      "Best Gamma: scale \n",
      "\n",
      "[[57  0  0  0  0]\n",
      " [ 0 14  0  0  0]\n",
      " [ 0  0 27  1  1]\n",
      " [ 2  0  0 29  1]\n",
      " [ 0  0  0  0 29]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        57\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      0.93      0.96        29\n",
      "           3       0.97      0.91      0.94        32\n",
      "           4       0.94      1.00      0.97        29\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.97      0.97      0.97       161\n",
      "weighted avg       0.97      0.97      0.97       161\n",
      "\n",
      "Training set score for svm_model: 0.996875\n",
      "Testing  set score for svm_model: 0.968944\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "\n",
    "\n",
    "test_data_ratio=[0.2]\n",
    "for i in test_data_ratio:\n",
    "    print(\"******************Start of iteration******************\\n\")\n",
    "    print(\"For ratio \",i)\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data_after_RF,labels,test_size=i,shuffle=True)\n",
    "    model = SVC()\n",
    "    params_grid = [{'kernel': ['linear'], 'C': [2]}]\n",
    "    svm_model = GridSearchCV(model, params_grid, cv=3)\n",
    "    svm_model.fit(X_train,y_train)\n",
    "    print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "    print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "    print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "    final_model = svm_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training set score for svm_model: %f\" % final_model.score(X_train , y_train))\n",
    "    print(\"Testing  set score for svm_model: %f\" % final_model.score(X_test  , y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ef4eaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "Splitting percentage is 5\n",
      "Shape of training input X_train: (40, 80)\n",
      "Shape of testing input X_test: (40, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.8754578754578755 \n",
      "\n",
      "Best C: 100 \n",
      "\n",
      "Best Kernel: linear \n",
      "\n",
      "Best Gamma: scale \n",
      "\n",
      "[[11  0  0  0  0]\n",
      " [ 0  5  0  0  0]\n",
      " [ 0  0  7  2  0]\n",
      " [ 3  0  0  3  4]\n",
      " [ 0  0  0  0  5]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        11\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      0.78      0.88         9\n",
      "           3       0.60      0.30      0.40        10\n",
      "           4       0.56      1.00      0.71         5\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.79      0.82      0.77        40\n",
      "weighted avg       0.79      0.78      0.75        40\n",
      "\n",
      "Training set score for svm_model: 1.000000\n",
      "Testing  set score for svm_model: 0.775000\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 10\n",
      "Shape of training input X_train: (80, 80)\n",
      "Shape of testing input X_test: (80, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.9259259259259259 \n",
      "\n",
      "Best C: 100 \n",
      "\n",
      "Best Kernel: linear \n",
      "\n",
      "Best Gamma: scale \n",
      "\n",
      "[[36  0  0  1  0]\n",
      " [ 0  5  0  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 4  0  0 10  0]\n",
      " [ 0  0  0  0 12]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        37\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       0.91      0.71      0.80        14\n",
      "           4       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.96      0.94      0.95        80\n",
      "weighted avg       0.94      0.94      0.93        80\n",
      "\n",
      "Training set score for svm_model: 1.000000\n",
      "Testing  set score for svm_model: 0.937500\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 15\n",
      "Shape of training input X_train: (120, 80)\n",
      "Shape of testing input X_test: (120, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.9166666666666666 \n",
      "\n",
      "Best C: 100 \n",
      "\n",
      "Best Kernel: linear \n",
      "\n",
      "Best Gamma: scale \n",
      "\n",
      "[[48  0  0  0  0]\n",
      " [ 0  9  0  0  0]\n",
      " [ 1  0 19  0  0]\n",
      " [ 2  1  1 16  0]\n",
      " [ 0  0  0  0 23]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        48\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       0.95      0.95      0.95        20\n",
      "           3       1.00      0.80      0.89        20\n",
      "           4       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.96       120\n",
      "   macro avg       0.96      0.95      0.95       120\n",
      "weighted avg       0.96      0.96      0.96       120\n",
      "\n",
      "Training set score for svm_model: 1.000000\n",
      "Testing  set score for svm_model: 0.958333\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 20\n",
      "Shape of training input X_train: (160, 80)\n",
      "Shape of testing input X_test: (160, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.8997204751921734 \n",
      "\n",
      "Best C: 100 \n",
      "\n",
      "Best Kernel: linear \n",
      "\n",
      "Best Gamma: scale \n",
      "\n",
      "[[54  0  0  2  0]\n",
      " [ 0 16  0  1  0]\n",
      " [ 0  0 26  3  0]\n",
      " [ 4  1  0 19  0]\n",
      " [ 0  0  0  0 34]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95        56\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       1.00      0.90      0.95        29\n",
      "           3       0.76      0.79      0.78        24\n",
      "           4       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           0.93       160\n",
      "   macro avg       0.93      0.92      0.92       160\n",
      "weighted avg       0.93      0.93      0.93       160\n",
      "\n",
      "Training set score for svm_model: 1.000000\n",
      "Testing  set score for svm_model: 0.931250\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 25\n",
      "Shape of training input X_train: (200, 80)\n",
      "Shape of testing input X_test: (200, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.9199457259158752 \n",
      "\n",
      "Best C: 100 \n",
      "\n",
      "Best Kernel: linear \n",
      "\n",
      "Best Gamma: scale \n",
      "\n",
      "[[77  0  0  0  0]\n",
      " [ 0 15  0  1  0]\n",
      " [ 1  0 37  0  0]\n",
      " [ 6  0  0 26  0]\n",
      " [ 0  0  0  0 37]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        77\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.96      0.81      0.88        32\n",
      "           4       1.00      1.00      1.00        37\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.98      0.94      0.96       200\n",
      "weighted avg       0.96      0.96      0.96       200\n",
      "\n",
      "Training set score for svm_model: 1.000000\n",
      "Testing  set score for svm_model: 0.960000\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "\n",
    "for i in range(len(spliting_position)-1):\n",
    "    print(\"******************Start of iteration******************\")\n",
    "    print(\"Splitting percentage is {}\".format(spliting_percentage[i]))\n",
    "    \n",
    "    X_train=pd.DataFrame(data_for_experiment.iloc[spliting_position[i]:spliting_position[i+1],:])\n",
    "    y_train=labels_for_experiment.iloc[spliting_position[i]:spliting_position[i+1]]\n",
    "    X_test=data_for_experiment.drop(X_train.index, axis=0).sample(len(X_train))\n",
    "    y_test=np.array(pd.DataFrame(labels_for_experiment,index=X_test.index))\n",
    "    \n",
    "    print(\"Shape of training input X_train: {}\".format(X_train.shape))\n",
    "    print(\"Shape of testing input X_test: {}\".format(X_test.shape))\n",
    "    print(\"Shape of training output Y_train: {}\".format(Y_train.shape))\n",
    "    print(\"Shape of testing output Y_test: {}\".format(Y_test.shape))\n",
    "    \n",
    "    model = SVC()\n",
    "    params_grid = [{'kernel': ['linear'], 'C': [100,150]}]\n",
    "    svm_model = GridSearchCV(model, params_grid, cv=3)\n",
    "    svm_model.fit(X_train,y_train)\n",
    "    print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "    print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "    print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "    final_model = svm_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training set score for svm_model: %f\" % final_model.score(X_train , y_train))\n",
    "    print(\"Testing  set score for svm_model: %f\" % final_model.score(X_test  , y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b2853",
   "metadata": {},
   "source": [
    "# ** Decision Tree **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1543568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.2\n",
      "Best score for training data: 0.8109560791540521 \n",
      "\n",
      "Best depth: 8 \n",
      "\n",
      "Best #features: None \n",
      "\n",
      "[[53  0  0  4  2]\n",
      " [ 0 15  0  1  0]\n",
      " [ 1  1 27  1  1]\n",
      " [ 4  1  0 24  2]\n",
      " [ 5  0  0  0 19]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        59\n",
      "           1       0.88      0.94      0.91        16\n",
      "           2       1.00      0.87      0.93        31\n",
      "           3       0.80      0.77      0.79        31\n",
      "           4       0.79      0.79      0.79        24\n",
      "\n",
      "    accuracy                           0.86       161\n",
      "   macro avg       0.86      0.85      0.86       161\n",
      "weighted avg       0.86      0.86      0.86       161\n",
      "\n",
      "Training set score for dc_model: 0.987500\n",
      "Testing  set score for dc_model: 0.857143\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "\n",
    "test_data_ratio=[0.2]\n",
    "for i in test_data_ratio:\n",
    "    print(\"******************Start of iteration******************\\n\")\n",
    "    print(\"For ratio \",i)\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data_after_RF,labels,test_size=i,shuffle=True)\n",
    "    model = DecisionTreeClassifier()\n",
    "    params_grid = [{'max_depth': [8,9,10,11,12],'random_state':[42]}]\n",
    "    dc_model = GridSearchCV(model, params_grid, cv=3)\n",
    "    dc_model.fit(X_train,y_train)\n",
    "    print('Best score for training data:', dc_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best depth:',dc_model.best_estimator_.max_depth,\"\\n\") \n",
    "    print('Best #features:',dc_model.best_estimator_.max_features,\"\\n\")\n",
    "    #print('Best Gamma:',dc_model.best_estimator_.,\"\\n\")\n",
    "    final_model = dc_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training set score for dc_model: %f\" % final_model.score(X_train , y_train))\n",
    "    print(\"Testing  set score for dc_model: %f\" % final_model.score(X_test  , y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37ebe3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "Splitting percentage is 5\n",
      "Shape of training input X_train: (40, 80)\n",
      "Shape of testing input X_test: (40, 80)\n",
      "Shape of training output Y_train: (40,)\n",
      "Shape of testing output Y_test: (40, 1)\n",
      "Best score for training data: 0.521978021978022 \n",
      "\n",
      "Best depth: 8 \n",
      "\n",
      "Best #features: None \n",
      "\n",
      "[[13  3  0  2  0]\n",
      " [ 1  2  0  0  0]\n",
      " [ 0  1  2  0  0]\n",
      " [ 1  3  1  5  3]\n",
      " [ 0  0  0  0  3]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79        18\n",
      "           1       0.22      0.67      0.33         3\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.71      0.38      0.50        13\n",
      "           4       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.62        40\n",
      "   macro avg       0.59      0.69      0.59        40\n",
      "weighted avg       0.73      0.62      0.64        40\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.625000\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 10\n",
      "Shape of training input X_train: (80, 80)\n",
      "Shape of testing input X_test: (80, 80)\n",
      "Shape of training output Y_train: (80,)\n",
      "Shape of testing output Y_test: (80, 1)\n",
      "Best score for training data: 0.6628679962013295 \n",
      "\n",
      "Best depth: 8 \n",
      "\n",
      "Best #features: None \n",
      "\n",
      "[[21  1  1  3  0]\n",
      " [ 1  4  1  1  0]\n",
      " [ 1  0 13  0  0]\n",
      " [ 6  1  1  4  2]\n",
      " [ 5  0  2  5  7]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70        26\n",
      "           1       0.67      0.57      0.62         7\n",
      "           2       0.72      0.93      0.81        14\n",
      "           3       0.31      0.29      0.30        14\n",
      "           4       0.78      0.37      0.50        19\n",
      "\n",
      "    accuracy                           0.61        80\n",
      "   macro avg       0.62      0.59      0.58        80\n",
      "weighted avg       0.62      0.61      0.59        80\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.612500\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 15\n",
      "Shape of training input X_train: (120, 80)\n",
      "Shape of testing input X_test: (120, 80)\n",
      "Shape of training output Y_train: (120,)\n",
      "Shape of testing output Y_test: (120, 1)\n",
      "Best score for training data: 0.7666666666666666 \n",
      "\n",
      "Best depth: 8 \n",
      "\n",
      "Best #features: None \n",
      "\n",
      "[[32  0  2  6  2]\n",
      " [ 1  9  1  1  0]\n",
      " [ 3  0 18  1  0]\n",
      " [ 8  0  0  8  6]\n",
      " [ 2  0  0  0 20]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73        42\n",
      "           1       1.00      0.75      0.86        12\n",
      "           2       0.86      0.82      0.84        22\n",
      "           3       0.50      0.36      0.42        22\n",
      "           4       0.71      0.91      0.80        22\n",
      "\n",
      "    accuracy                           0.73       120\n",
      "   macro avg       0.75      0.72      0.73       120\n",
      "weighted avg       0.72      0.72      0.72       120\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.725000\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 20\n",
      "Shape of training input X_train: (160, 80)\n",
      "Shape of testing input X_test: (160, 80)\n",
      "Shape of training output Y_train: (160,)\n",
      "Shape of testing output Y_test: (160, 1)\n",
      "Best score for training data: 0.6872816212438854 \n",
      "\n",
      "Best depth: 8 \n",
      "\n",
      "Best #features: None \n",
      "\n",
      "[[43  1  3 10  3]\n",
      " [ 0 13  0  3  0]\n",
      " [ 0  0 18  3  1]\n",
      " [ 6  2  1 20  3]\n",
      " [ 5  0  0  1 24]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.75        60\n",
      "           1       0.81      0.81      0.81        16\n",
      "           2       0.82      0.82      0.82        22\n",
      "           3       0.54      0.62      0.58        32\n",
      "           4       0.77      0.80      0.79        30\n",
      "\n",
      "    accuracy                           0.74       160\n",
      "   macro avg       0.75      0.75      0.75       160\n",
      "weighted avg       0.75      0.74      0.74       160\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.737500\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 25\n",
      "Shape of training input X_train: (200, 80)\n",
      "Shape of testing input X_test: (200, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.73013719282376 \n",
      "\n",
      "Best depth: 8 \n",
      "\n",
      "Best #features: None \n",
      "\n",
      "[[51  0  0 20  6]\n",
      " [ 5 12  0  0  0]\n",
      " [ 2  0 30  4  1]\n",
      " [ 4  2  0 25  8]\n",
      " [ 3  0  0  4 23]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.72        77\n",
      "           1       0.86      0.71      0.77        17\n",
      "           2       1.00      0.81      0.90        37\n",
      "           3       0.47      0.64      0.54        39\n",
      "           4       0.61      0.77      0.68        30\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.74      0.72      0.72       200\n",
      "weighted avg       0.74      0.70      0.72       200\n",
      "\n",
      "Training set score for dc_model: 0.995000\n",
      "Testing  set score for dc_model: 0.705000\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "\n",
    "for i in range(len(spliting_position)-1):\n",
    "    print(\"******************Start of iteration******************\")\n",
    "    print(\"Splitting percentage is {}\".format(spliting_percentage[i]))\n",
    "    \n",
    "    X_train=pd.DataFrame(data_for_experiment.iloc[spliting_position[i]:spliting_position[i+1],:])\n",
    "    Y_train=labels_for_experiment.iloc[spliting_position[i]:spliting_position[i+1]]\n",
    "    X_test=data_for_experiment.drop(X_train.index, axis=0).sample(len(X_train))\n",
    "    Y_test=np.array(pd.DataFrame(labels_for_experiment,index=X_test.index))\n",
    "    \n",
    "    print(\"Shape of training input X_train: {}\".format(X_train.shape))\n",
    "    print(\"Shape of testing input X_test: {}\".format(X_test.shape))\n",
    "    print(\"Shape of training output Y_train: {}\".format(Y_train.shape))\n",
    "    print(\"Shape of testing output Y_test: {}\".format(Y_test.shape))\n",
    "    \n",
    "    model = DecisionTreeClassifier()\n",
    "    params_grid = [{'max_depth': [8,9,10,11,12],'random_state':[42]}]\n",
    "    dc_model = GridSearchCV(model, params_grid, cv=3)\n",
    "    dc_model.fit(X_train,Y_train)\n",
    "    print('Best score for training data:', dc_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best depth:',dc_model.best_estimator_.max_depth,\"\\n\") \n",
    "    print('Best #features:',dc_model.best_estimator_.max_features,\"\\n\")\n",
    "    #print('Best Gamma:',dc_model.best_estimator_.,\"\\n\")\n",
    "    final_model = dc_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    Y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(Y_test,Y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(Y_test,Y_pred))\n",
    "    print(\"Training set score for dc_model: %f\" % final_model.score(X_train , Y_train))\n",
    "    print(\"Testing  set score for dc_model: %f\" % final_model.score(X_test  , Y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0b5b6",
   "metadata": {},
   "source": [
    "<h1> **************************************************************************************************************</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e22d6",
   "metadata": {},
   "source": [
    " <h1> AdaBoost </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18f300b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.3\n",
      "Best score for training data: 0.8231652387250111 \n",
      "\n",
      "Best estimator: 4 \n",
      "\n",
      "Best #learning rate: 0.1 \n",
      "\n",
      "Best algorithm: SAMME \n",
      "\n",
      "[[79  0  1  6  4]\n",
      " [ 0 25  0  0  0]\n",
      " [ 1  1 38  1  0]\n",
      " [13  4  0 28  1]\n",
      " [ 2  0  0  5 32]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85        90\n",
      "           1       0.83      1.00      0.91        25\n",
      "           2       0.97      0.93      0.95        41\n",
      "           3       0.70      0.61      0.65        46\n",
      "           4       0.86      0.82      0.84        39\n",
      "\n",
      "    accuracy                           0.84       241\n",
      "   macro avg       0.84      0.85      0.84       241\n",
      "weighted avg       0.84      0.84      0.84       241\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.838174\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.25\n",
      "Best score for training data: 0.82 \n",
      "\n",
      "Best estimator: 2 \n",
      "\n",
      "Best #learning rate: 1.0 \n",
      "\n",
      "Best algorithm: SAMME.R \n",
      "\n",
      "[[61  0  1  8  5]\n",
      " [ 1 18  0  2  0]\n",
      " [ 1  1 40  0  1]\n",
      " [10  0  1 19  2]\n",
      " [ 3  0  0  2 25]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81        75\n",
      "           1       0.95      0.86      0.90        21\n",
      "           2       0.95      0.93      0.94        43\n",
      "           3       0.61      0.59      0.60        32\n",
      "           4       0.76      0.83      0.79        30\n",
      "\n",
      "    accuracy                           0.81       201\n",
      "   macro avg       0.81      0.81      0.81       201\n",
      "weighted avg       0.81      0.81      0.81       201\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.810945\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.2\n",
      "Best score for training data: 0.828053471399529 \n",
      "\n",
      "Best estimator: 4 \n",
      "\n",
      "Best #learning rate: 1.0 \n",
      "\n",
      "Best algorithm: SAMME.R \n",
      "\n",
      "[[49  2  0  7  3]\n",
      " [ 0 12  0  0  0]\n",
      " [ 0  0 29  1  0]\n",
      " [ 9  0  1 22  2]\n",
      " [ 1  0  0  2 21]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82        61\n",
      "           1       0.86      1.00      0.92        12\n",
      "           2       0.97      0.97      0.97        30\n",
      "           3       0.69      0.65      0.67        34\n",
      "           4       0.81      0.88      0.84        24\n",
      "\n",
      "    accuracy                           0.83       161\n",
      "   macro avg       0.83      0.86      0.84       161\n",
      "weighted avg       0.82      0.83      0.82       161\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.826087\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.15\n",
      "Best score for training data: 0.8132171585253336 \n",
      "\n",
      "Best estimator: 4 \n",
      "\n",
      "Best #learning rate: 1.0 \n",
      "\n",
      "Best algorithm: SAMME.R \n",
      "\n",
      "[[43  0  1  7  3]\n",
      " [ 1 12  0  0  0]\n",
      " [ 0  0 23  1  0]\n",
      " [ 2  1  0 12  1]\n",
      " [ 1  0  0  3 10]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85        54\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.96      0.96      0.96        24\n",
      "           3       0.52      0.75      0.62        16\n",
      "           4       0.71      0.71      0.71        14\n",
      "\n",
      "    accuracy                           0.83       121\n",
      "   macro avg       0.81      0.83      0.81       121\n",
      "weighted avg       0.85      0.83      0.83       121\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.826446\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.1\n",
      "Best score for training data: 0.8083333333333332 \n",
      "\n",
      "Best estimator: 2 \n",
      "\n",
      "Best #learning rate: 0.1 \n",
      "\n",
      "Best algorithm: SAMME.R \n",
      "\n",
      "[[20  0  0  5  1]\n",
      " [ 0  9  0  0  0]\n",
      " [ 0  1 14  1  0]\n",
      " [ 8  2  0  9  1]\n",
      " [ 1  0  0  0  9]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73        26\n",
      "           1       0.75      1.00      0.86         9\n",
      "           2       1.00      0.88      0.93        16\n",
      "           3       0.60      0.45      0.51        20\n",
      "           4       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.75        81\n",
      "   macro avg       0.77      0.80      0.78        81\n",
      "weighted avg       0.75      0.75      0.75        81\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.753086\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.05\n",
      "Best score for training data: 0.8341788304129967 \n",
      "\n",
      "Best estimator: 4 \n",
      "\n",
      "Best #learning rate: 1.0 \n",
      "\n",
      "Best algorithm: SAMME \n",
      "\n",
      "[[11  0  0  1  2]\n",
      " [ 0  6  0  0  0]\n",
      " [ 0  0  9  0  0]\n",
      " [ 2  1  0  5  0]\n",
      " [ 0  0  0  0  4]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.81        14\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       1.00      1.00      1.00         9\n",
      "           3       0.83      0.62      0.71         8\n",
      "           4       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.85        41\n",
      "   macro avg       0.84      0.88      0.85        41\n",
      "weighted avg       0.86      0.85      0.85        41\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.853659\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "\n",
    "test_data_ratio=[0.3,0.25,0.2,0.15,0.1,0.05]\n",
    "for i in test_data_ratio:\n",
    "    print(\"******************Start of iteration******************\\n\")\n",
    "    print(\"For ratio \",i)\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data_after_RF,labels,test_size=i,shuffle=True)\n",
    "    model = DecisionTreeClassifier(max_features=None)\n",
    "    params_grid = [{'n_estimators':[2,4],'learning_rate':[1.0,1e-1,1e-2],'algorithm':['SAMME.R','SAMME']}]\n",
    "    model_ada=AdaBoostClassifier(model,)\n",
    "    dc_model = GridSearchCV(model_ada, params_grid, cv=3)\n",
    "    dc_model.fit(X_train,y_train)\n",
    "    print('Best score for training data:', dc_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best estimator:',dc_model.best_estimator_.n_estimators,\"\\n\") \n",
    "    print('Best #learning rate:',dc_model.best_estimator_.learning_rate,\"\\n\")\n",
    "    print('Best algorithm:',dc_model.best_estimator_.algorithm,\"\\n\")\n",
    "    final_model = dc_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training set score for dc_model: %f\" % final_model.score(X_train , y_train))\n",
    "    print(\"Testing  set score for dc_model: %f\" % final_model.score(X_test  , y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4501268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "Splitting percentage is 5\n",
      "Shape of training input X_train: (40, 80)\n",
      "Shape of testing input X_test: (40, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.5750915750915752 \n",
      "\n",
      "Best estimator: 2 \n",
      "\n",
      "Best #learning rate: 1.0 \n",
      "\n",
      "Best algorithm: SAMME.R \n",
      "\n",
      "[[12  1  0  1  0]\n",
      " [ 1  4  0  0  0]\n",
      " [ 0  0  6  1  0]\n",
      " [ 5  2  0  3  1]\n",
      " [ 0  0  0  0  3]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75        14\n",
      "           1       0.57      0.80      0.67         5\n",
      "           2       1.00      0.86      0.92         7\n",
      "           3       0.60      0.27      0.37        11\n",
      "           4       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.72      0.76      0.71        40\n",
      "weighted avg       0.70      0.70      0.67        40\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.700000\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 10\n",
      "Shape of training input X_train: (80, 80)\n",
      "Shape of testing input X_test: (80, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.7625830959164293 \n",
      "\n",
      "Best estimator: 4 \n",
      "\n",
      "Best #learning rate: 1.0 \n",
      "\n",
      "Best algorithm: SAMME \n",
      "\n",
      "[[24  0  2  2  1]\n",
      " [ 1  3  0  0  0]\n",
      " [ 1  0 11  0  1]\n",
      " [ 4  1  2  4  2]\n",
      " [ 4  0  0  6 11]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.76        29\n",
      "           1       0.75      0.75      0.75         4\n",
      "           2       0.73      0.85      0.79        13\n",
      "           3       0.33      0.31      0.32        13\n",
      "           4       0.73      0.52      0.61        21\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.65      0.65      0.65        80\n",
      "weighted avg       0.66      0.66      0.65        80\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.662500\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 15\n",
      "Shape of training input X_train: (120, 80)\n",
      "Shape of testing input X_test: (120, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.8000000000000002 \n",
      "\n",
      "Best estimator: 4 \n",
      "\n",
      "Best #learning rate: 1.0 \n",
      "\n",
      "Best algorithm: SAMME.R \n",
      "\n",
      "[[25  0  3  2  5]\n",
      " [ 0  9  4  1  0]\n",
      " [ 0  0 14  3  0]\n",
      " [ 6  0  1 13  5]\n",
      " [ 0  0  1  1 27]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76        35\n",
      "           1       1.00      0.64      0.78        14\n",
      "           2       0.61      0.82      0.70        17\n",
      "           3       0.65      0.52      0.58        25\n",
      "           4       0.73      0.93      0.82        29\n",
      "\n",
      "    accuracy                           0.73       120\n",
      "   macro avg       0.76      0.73      0.73       120\n",
      "weighted avg       0.75      0.73      0.73       120\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.733333\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 20\n",
      "Shape of training input X_train: (160, 80)\n",
      "Shape of testing input X_test: (160, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.7310738411367342 \n",
      "\n",
      "Best estimator: 4 \n",
      "\n",
      "Best #learning rate: 1.0 \n",
      "\n",
      "Best algorithm: SAMME.R \n",
      "\n",
      "[[51  0  2  7  2]\n",
      " [ 0 15  0  1  0]\n",
      " [ 0  0 26  3  1]\n",
      " [12  1  0 13  0]\n",
      " [ 4  0  0  2 20]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        62\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       0.93      0.87      0.90        30\n",
      "           3       0.50      0.50      0.50        26\n",
      "           4       0.87      0.77      0.82        26\n",
      "\n",
      "    accuracy                           0.78       160\n",
      "   macro avg       0.80      0.78      0.79       160\n",
      "weighted avg       0.79      0.78      0.78       160\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.781250\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 25\n",
      "Shape of training input X_train: (200, 80)\n",
      "Shape of testing input X_test: (200, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.7401628222523744 \n",
      "\n",
      "Best estimator: 2 \n",
      "\n",
      "Best #learning rate: 1.0 \n",
      "\n",
      "Best algorithm: SAMME \n",
      "\n",
      "[[63  0  1  8  2]\n",
      " [ 0 21  0  1  1]\n",
      " [ 3  0 26  3  1]\n",
      " [ 6  0  1 24  2]\n",
      " [ 3  0  0  4 30]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85        74\n",
      "           1       1.00      0.91      0.95        23\n",
      "           2       0.93      0.79      0.85        33\n",
      "           3       0.60      0.73      0.66        33\n",
      "           4       0.83      0.81      0.82        37\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.84      0.82      0.83       200\n",
      "weighted avg       0.83      0.82      0.82       200\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.820000\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "\n",
    "\n",
    "for i in range(len(spliting_position)-1):\n",
    "    print(\"******************Start of iteration******************\")\n",
    "    print(\"Splitting percentage is {}\".format(spliting_percentage[i]))\n",
    "    \n",
    "    X_train=pd.DataFrame(data_for_experiment.iloc[spliting_position[i]:spliting_position[i+1],:])\n",
    "    y_train=labels_for_experiment.iloc[spliting_position[i]:spliting_position[i+1]]\n",
    "    X_test=data_for_experiment.drop(X_train.index, axis=0).sample(len(X_train))\n",
    "    y_test=np.array(pd.DataFrame(labels_for_experiment,index=X_test.index))\n",
    "    \n",
    "    print(\"Shape of training input X_train: {}\".format(X_train.shape))\n",
    "    print(\"Shape of testing input X_test: {}\".format(X_test.shape))\n",
    "    print(\"Shape of training output Y_train: {}\".format(Y_train.shape))\n",
    "    print(\"Shape of testing output Y_test: {}\".format(Y_test.shape))\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_features=None)\n",
    "    params_grid = [{'n_estimators':[2,4],'learning_rate':[1.0,1e-1,1e-2],'algorithm':['SAMME.R','SAMME']}]\n",
    "    model_ada=AdaBoostClassifier(model,)\n",
    "    dc_model = GridSearchCV(model_ada, params_grid, cv=3)\n",
    "    dc_model.fit(X_train,y_train)\n",
    "    print('Best score for training data:', dc_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best estimator:',dc_model.best_estimator_.n_estimators,\"\\n\") \n",
    "    print('Best #learning rate:',dc_model.best_estimator_.learning_rate,\"\\n\")\n",
    "    print('Best algorithm:',dc_model.best_estimator_.algorithm,\"\\n\")\n",
    "    final_model = dc_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training set score for dc_model: %f\" % final_model.score(X_train , y_train))\n",
    "    print(\"Testing  set score for dc_model: %f\" % final_model.score(X_test  , y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013bf29",
   "metadata": {},
   "source": [
    "# ** Ensemble Learning **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c91abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.2\n",
      "[[60  0  0  1  0]\n",
      " [ 0 17  0  0  0]\n",
      " [ 1  0 26  0  0]\n",
      " [ 1  1  0 23  0]\n",
      " [ 0  0  0  0 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98        61\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.96      0.98        27\n",
      "           3       0.96      0.92      0.94        25\n",
      "           4       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.97      0.97      0.97       161\n",
      "weighted avg       0.98      0.98      0.98       161\n",
      "\n",
      "Training set score for EL: 1.000000\n",
      "Testing  set score for EL: 0.975155\n",
      "Hard Voting Score  0\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_ratio=[0.20]\n",
    "for i in test_data_ratio:\n",
    "    print(\"******************Start of iteration******************\\n\")\n",
    "    print(\"For ratio \",i)\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data_after_RF,labels,test_size=i,shuffle=True)\n",
    "    estimator = []\n",
    "    # make different combination in the ensemble classfier\n",
    "    estimator.append(('lr',LogisticRegression(solver='saga',penalty='l1',C=1,n_jobs=2)))\n",
    "    estimator.append(('SVC', SVC(gamma ='scale',probability=True,C=100,kernel='linear',)))\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=14,criterion='gini', splitter='best', min_samples_split=17,random_state=42)\n",
    "    model = AdaBoostClassifier(base_estimator=base_estimator,n_estimators=250 ,learning_rate=1,algorithm='SAMME',random_state=7)\n",
    "    estimator.append(('DTC', model))\n",
    "    #estimator.append(('svc_rbf',SVC(gamma ='auto',C=4,kernel='rbf',)))\n",
    "\n",
    "\n",
    "    vot_hard = VotingClassifier(estimators = estimator, voting ='soft')\n",
    "    vot_hard.fit(X_train,y_train)\n",
    "    Y_pred = vot_hard.predict(X_test)\n",
    "    \n",
    "    print(confusion_matrix(y_test,Y_pred))\n",
    "    print(classification_report(y_test,Y_pred))\n",
    "    print(\"Training set score for EL: %f\" % vot_hard.score(X_train , y_train))\n",
    "    print(\"Testing  set score for EL: %f\" % vot_hard.score(X_test  , y_test ))\n",
    "    \n",
    "\n",
    "    score = accuracy_score(y_test, Y_pred)\n",
    "    print(\"Hard Voting Score % d\" % score)\n",
    "    \n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a56fad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "Splitting percentage is 5\n",
      "Shape of training input X_train: (40, 80)\n",
      "Shape of testing input X_test: (40, 80)\n",
      "Shape of training output Y_train: (40,)\n",
      "Shape of testing output Y_test: (40, 1)\n",
      "[[9 0 0 0 0]\n",
      " [0 4 0 0 0]\n",
      " [2 0 9 0 0]\n",
      " [6 0 0 1 2]\n",
      " [0 0 0 0 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69         9\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      0.82      0.90        11\n",
      "           3       1.00      0.11      0.20         9\n",
      "           4       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.86      0.79      0.73        40\n",
      "weighted avg       0.86      0.75      0.70        40\n",
      "\n",
      "Training set score for EL: 1.000000\n",
      "Testing  set score for EL: 0.750000\n",
      "Hard Voting Score  0\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 10\n",
      "Shape of training input X_train: (80, 80)\n",
      "Shape of testing input X_test: (80, 80)\n",
      "Shape of training output Y_train: (80,)\n",
      "Shape of testing output Y_test: (80, 1)\n",
      "[[31  0  0  1  0]\n",
      " [ 0  4  0  0  0]\n",
      " [ 0  0 16  1  0]\n",
      " [ 3  0  0  8  0]\n",
      " [ 0  0  0  0 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        32\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      0.94      0.97        17\n",
      "           3       0.80      0.73      0.76        11\n",
      "           4       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.94      0.93      0.93        80\n",
      "weighted avg       0.94      0.94      0.94        80\n",
      "\n",
      "Training set score for EL: 1.000000\n",
      "Testing  set score for EL: 0.937500\n",
      "Hard Voting Score  0\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 15\n",
      "Shape of training input X_train: (120, 80)\n",
      "Shape of testing input X_test: (120, 80)\n",
      "Shape of training output Y_train: (120,)\n",
      "Shape of testing output Y_test: (120, 1)\n",
      "[[45  0  0  0  0]\n",
      " [ 0  9  0  0  0]\n",
      " [ 1  0 18  0  0]\n",
      " [ 3  2  0 16  2]\n",
      " [ 0  0  0  0 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        45\n",
      "           1       0.82      1.00      0.90         9\n",
      "           2       1.00      0.95      0.97        19\n",
      "           3       1.00      0.70      0.82        23\n",
      "           4       0.92      1.00      0.96        24\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.93      0.93      0.92       120\n",
      "weighted avg       0.94      0.93      0.93       120\n",
      "\n",
      "Training set score for EL: 1.000000\n",
      "Testing  set score for EL: 0.933333\n",
      "Hard Voting Score  0\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 20\n",
      "Shape of training input X_train: (160, 80)\n",
      "Shape of testing input X_test: (160, 80)\n",
      "Shape of training output Y_train: (160,)\n",
      "Shape of testing output Y_test: (160, 1)\n",
      "[[47  0  0  4  0]\n",
      " [ 0 17  0  1  0]\n",
      " [ 0  0 30  0  1]\n",
      " [ 4  1  0 26  1]\n",
      " [ 0  0  0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        51\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       1.00      0.97      0.98        31\n",
      "           3       0.84      0.81      0.83        32\n",
      "           4       0.93      1.00      0.97        28\n",
      "\n",
      "    accuracy                           0.93       160\n",
      "   macro avg       0.93      0.93      0.93       160\n",
      "weighted avg       0.92      0.93      0.92       160\n",
      "\n",
      "Training set score for EL: 1.000000\n",
      "Testing  set score for EL: 0.925000\n",
      "Hard Voting Score  0\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 25\n",
      "Shape of training input X_train: (200, 80)\n",
      "Shape of testing input X_test: (200, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "[[80  0  0  0  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 37  1  0]\n",
      " [ 3  0  0 34  0]\n",
      " [ 0  0  0  0 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        80\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.97      0.92      0.94        37\n",
      "           4       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.99      0.98      0.98       200\n",
      "weighted avg       0.98      0.98      0.98       200\n",
      "\n",
      "Training set score for EL: 1.000000\n",
      "Testing  set score for EL: 0.980000\n",
      "Hard Voting Score  0\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(spliting_position)-1):\n",
    "    print(\"******************Start of iteration******************\")\n",
    "    print(\"Splitting percentage is {}\".format(spliting_percentage[i]))\n",
    "    \n",
    "    X_train=pd.DataFrame(data_for_experiment.iloc[spliting_position[i]:spliting_position[i+1],:])\n",
    "    Y_train=labels_for_experiment.iloc[spliting_position[i]:spliting_position[i+1]]\n",
    "    X_test=data_for_experiment.drop(X_train.index, axis=0).sample(len(X_train))\n",
    "    Y_test=np.array(pd.DataFrame(labels_for_experiment,index=X_test.index))\n",
    "    \n",
    "    print(\"Shape of training input X_train: {}\".format(X_train.shape))\n",
    "    print(\"Shape of testing input X_test: {}\".format(X_test.shape))\n",
    "    print(\"Shape of training output Y_train: {}\".format(Y_train.shape))\n",
    "    print(\"Shape of testing output Y_test: {}\".format(Y_test.shape))\n",
    "    \n",
    "    estimator = []\n",
    "    # make different combination in the ensemble classfier\n",
    "    estimator.append(('lr',LogisticRegression(solver='saga',penalty='l1',C=1,n_jobs=2)))\n",
    "    estimator.append(('SVC', SVC(gamma ='scale',probability=True,C=100,kernel='linear',)))\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=14,criterion='gini', splitter='best', min_samples_split=17,random_state=42)\n",
    "    model = AdaBoostClassifier(base_estimator=base_estimator,n_estimators=250 ,learning_rate=1,algorithm='SAMME',random_state=7)\n",
    "    estimator.append(('DTC', model))\n",
    "    #estimator.append(('svc_rbf',SVC(gamma ='auto',C=4,kernel='rbf',)))\n",
    "\n",
    "\n",
    "    vot_hard = VotingClassifier(estimators = estimator, voting ='soft')\n",
    "    vot_hard.fit(X_train,Y_train)\n",
    "    Y_pred = vot_hard.predict(X_test)\n",
    "    \n",
    "    print(confusion_matrix(Y_test,Y_pred))\n",
    "    print(classification_report(Y_test,Y_pred))\n",
    "    print(\"Training set score for EL: %f\" % vot_hard.score(X_train , Y_train))\n",
    "    print(\"Testing  set score for EL: %f\" % vot_hard.score(X_test  , Y_test ))\n",
    "    \n",
    "\n",
    "    score = accuracy_score(Y_test, Y_pred)\n",
    "    print(\"Hard Voting Score % d\" % score)\n",
    "    \n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0b5b6",
   "metadata": {},
   "source": [
    "# ** Random Forest **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c9587e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "\n",
      "For ratio  0.2\n",
      "Best score for training data: 0.9515525134190397 \n",
      "\n",
      "Best depth: 7 \n",
      "\n",
      "Best #estimators: 100 \n",
      "\n",
      "Best jobs: 10 \n",
      "\n",
      "[[64  0  0  0  0]\n",
      " [ 1 18  0  0  0]\n",
      " [ 1  0 28  0  0]\n",
      " [ 9  0  0 17  0]\n",
      " [ 3  0  0  0 20]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        64\n",
      "           1       1.00      0.95      0.97        19\n",
      "           2       1.00      0.97      0.98        29\n",
      "           3       1.00      0.65      0.79        26\n",
      "           4       1.00      0.87      0.93        23\n",
      "\n",
      "    accuracy                           0.91       161\n",
      "   macro avg       0.96      0.89      0.92       161\n",
      "weighted avg       0.93      0.91      0.91       161\n",
      "\n",
      "Training set score for dc_model: 0.998437\n",
      "Testing  set score for dc_model: 0.913043\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "\n",
    "test_data_ratio=[0.2]\n",
    "for i in test_data_ratio:\n",
    "    print(\"******************Start of iteration******************\\n\")\n",
    "    print(\"For ratio \",i)\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data_after_RF,labels,test_size=i,shuffle=True)\n",
    "    model = RandomForestClassifier()\n",
    "    params_grid = [{'max_depth': [5,6,7],'random_state':[42],'n_jobs':[10,15,20]}]\n",
    "    dc_model = GridSearchCV(model, params_grid, cv=3)\n",
    "    dc_model.fit(X_train,y_train)\n",
    "    print('Best score for training data:', dc_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best depth:',dc_model.best_estimator_.max_depth,\"\\n\") \n",
    "    print('Best #estimators:',dc_model.best_estimator_.n_estimators,\"\\n\")\n",
    "    print('Best jobs:',dc_model.best_estimator_.n_jobs,\"\\n\") \n",
    "    #print('Best #features:',dc_model.best_estimator_.max_features,\"\\n\")\n",
    "    #print('Best Gamma:',dc_model.best_estimator_.,\"\\n\")\n",
    "    final_model = dc_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training set score for dc_model: %f\" % final_model.score(X_train , y_train))\n",
    "    print(\"Testing  set score for dc_model: %f\" % final_model.score(X_test  , y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb66d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Start of iteration******************\n",
      "Splitting percentage is 5\n",
      "Shape of training input X_train: (40, 80)\n",
      "Shape of testing input X_test: (40, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.8241758241758242 \n",
      "\n",
      "Best depth: 5 \n",
      "\n",
      "Best #estimators: 100 \n",
      "\n",
      "Best jobs: 2 \n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 0  3  0  0  0]\n",
      " [ 0  0  8  0  0]\n",
      " [ 7  0  0  0  1]\n",
      " [ 0  0  0  0  8]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        13\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.80        40\n",
      "   macro avg       0.71      0.80      0.75        40\n",
      "weighted avg       0.66      0.80      0.72        40\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.800000\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 10\n",
      "Shape of training input X_train: (80, 80)\n",
      "Shape of testing input X_test: (80, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luhar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luhar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luhar\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.8509021842355176 \n",
      "\n",
      "Best depth: 6 \n",
      "\n",
      "Best #estimators: 100 \n",
      "\n",
      "Best jobs: 2 \n",
      "\n",
      "[[31  0  0  0  0]\n",
      " [ 0  8  0  0  0]\n",
      " [ 0  0 16  0  1]\n",
      " [13  0  1  4  0]\n",
      " [ 2  0  0  0  4]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.81        31\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       0.94      0.94      0.94        17\n",
      "           3       1.00      0.22      0.36        18\n",
      "           4       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.79        80\n",
      "   macro avg       0.88      0.77      0.77        80\n",
      "weighted avg       0.85      0.79      0.75        80\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.787500\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 15\n",
      "Shape of training input X_train: (120, 80)\n",
      "Shape of testing input X_test: (120, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.9166666666666666 \n",
      "\n",
      "Best depth: 6 \n",
      "\n",
      "Best #estimators: 100 \n",
      "\n",
      "Best jobs: 2 \n",
      "\n",
      "[[38  0  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 8  0  0 10  0]\n",
      " [ 0  0  0  0 29]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89        39\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        21\n",
      "           3       0.91      0.56      0.69        18\n",
      "           4       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.95      0.91      0.92       120\n",
      "weighted avg       0.93      0.93      0.92       120\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.925000\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 20\n",
      "Shape of training input X_train: (160, 80)\n",
      "Shape of testing input X_test: (160, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.9125320288842301 \n",
      "\n",
      "Best depth: 7 \n",
      "\n",
      "Best #estimators: 100 \n",
      "\n",
      "Best jobs: 2 \n",
      "\n",
      "[[51  0  0  3  0]\n",
      " [ 1 24  0  0  0]\n",
      " [ 0  0 21  1  0]\n",
      " [ 3  0  0 26  0]\n",
      " [ 0  0  0  0 30]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94        54\n",
      "           1       1.00      0.96      0.98        25\n",
      "           2       1.00      0.95      0.98        22\n",
      "           3       0.87      0.90      0.88        29\n",
      "           4       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.95       160\n",
      "   macro avg       0.96      0.95      0.95       160\n",
      "weighted avg       0.95      0.95      0.95       160\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.950000\n",
      "******************End of iteration******************\n",
      "\n",
      "******************Start of iteration******************\n",
      "Splitting percentage is 25\n",
      "Shape of training input X_train: (200, 80)\n",
      "Shape of testing input X_test: (200, 80)\n",
      "Shape of training output Y_train: (200,)\n",
      "Shape of testing output Y_test: (200, 1)\n",
      "Best score for training data: 0.8951454846977235 \n",
      "\n",
      "Best depth: 6 \n",
      "\n",
      "Best #estimators: 100 \n",
      "\n",
      "Best jobs: 2 \n",
      "\n",
      "[[82  0  0  0  0]\n",
      " [ 1 21  0  0  0]\n",
      " [ 0  0 38  0  0]\n",
      " [10  0  0 21  1]\n",
      " [ 1  0  0  0 25]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        82\n",
      "           1       1.00      0.95      0.98        22\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      0.66      0.79        32\n",
      "           4       0.96      0.96      0.96        26\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.97      0.91      0.93       200\n",
      "weighted avg       0.94      0.94      0.93       200\n",
      "\n",
      "Training set score for dc_model: 1.000000\n",
      "Testing  set score for dc_model: 0.935000\n",
      "******************End of iteration******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing part\n",
    "\n",
    "for i in range(len(spliting_position)-1):\n",
    "    print(\"******************Start of iteration******************\")\n",
    "    print(\"Splitting percentage is {}\".format(spliting_percentage[i]))\n",
    "    \n",
    "    X_train=pd.DataFrame(data_for_experiment.iloc[spliting_position[i]:spliting_position[i+1],:])\n",
    "    y_train=labels_for_experiment.iloc[spliting_position[i]:spliting_position[i+1]]\n",
    "    X_test=data_for_experiment.drop(X_train.index, axis=0).sample(len(X_train))\n",
    "    y_test=np.array(pd.DataFrame(labels_for_experiment,index=X_test.index))\n",
    "    \n",
    "    print(\"Shape of training input X_train: {}\".format(X_train.shape))\n",
    "    print(\"Shape of testing input X_test: {}\".format(X_test.shape))\n",
    "    print(\"Shape of training output Y_train: {}\".format(Y_train.shape))\n",
    "    print(\"Shape of testing output Y_test: {}\".format(Y_test.shape))\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    params_grid = [{'max_depth': [5,6,7],'random_state':[42],'n_jobs':[2]}]\n",
    "    dc_model = GridSearchCV(model, params_grid, cv=3)\n",
    "    dc_model.fit(X_train,y_train)\n",
    "    print('Best score for training data:', dc_model.best_score_,\"\\n\") \n",
    "\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best depth:',dc_model.best_estimator_.max_depth,\"\\n\") \n",
    "    print('Best #estimators:',dc_model.best_estimator_.n_estimators,\"\\n\")\n",
    "    print('Best jobs:',dc_model.best_estimator_.n_jobs,\"\\n\") \n",
    "    #print('Best #features:',dc_model.best_estimator_.max_features,\"\\n\")\n",
    "    #print('Best Gamma:',dc_model.best_estimator_.,\"\\n\")\n",
    "    final_model = dc_model.best_estimator_\n",
    "\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training set score for dc_model: %f\" % final_model.score(X_train , y_train))\n",
    "    print(\"Testing  set score for dc_model: %f\" % final_model.score(X_test  , y_test ))\n",
    "\n",
    "    print(\"******************End of iteration******************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2fe81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "414dcb54",
   "metadata": {},
   "source": [
    "# ...........THANK YOU.........HAPPY CODING......."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
